{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gustavo Paciléo Borba\n",
    "\n",
    "Nome: Julia de Carvalho Figueiredo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\gubor\\OneDrive\\Documentos\\Projeto\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'coca-cola-projeto.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esqueci q coca cola engorda vou vomita</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faltou a coca cola afe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ela servindo ate em comercial mdssss o esmurro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoje a experiência gastronômica aqui de casa f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pipoca coca cola celular no carregar vendo as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica\n",
       "0             esqueci q coca cola engorda vou vomita           0\n",
       "1                             faltou a coca cola afe           1\n",
       "2  ela servindo ate em comercial mdssss o esmurro...           0\n",
       "3  hoje a experiência gastronômica aqui de casa f...           0\n",
       "4  pipoca coca cola celular no carregar vendo as ...           1"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lilkayfr_ uma coca-cola seria melhor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@henricostaa água, coca cola e maizena. tiro e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@gfmitsuya meu irmao derrubou coca cola nele n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depois de 2 e 17 dias eu voltei a beber um cop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o todynho pra segurar a onda do infarto do ene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica\n",
       "0              @lilkayfr_ uma coca-cola seria melhor           1\n",
       "1  @henricostaa água, coca cola e maizena. tiro e...           0\n",
       "2  @gfmitsuya meu irmao derrubou coca cola nele n...           0\n",
       "3  depois de 2 e 17 dias eu voltei a beber um cop...           0\n",
       "4  o todynho pra segurar a onda do infarto do ene...           0"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "No nosso projeto, decidimos analisar os tweets relacionados ao produto Coca-cola e assim classificamos como relevante todos tweets que apresentam opinião positiva em relação a esse refrigerante, e como irrelevantes aqueles que apresentam um opinião contra ao produto ou que não demontra posicionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removendo [!-.:?;@]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-624-050129bfa610>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Treinamento[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(train.shape[0]):\n",
    "    lista=cleanup(train.Treinamento[linha]).lower()\n",
    "    train.Treinamento[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Removendo espaços e emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "# search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-626-638747a86c95>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Treinamento[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(train.shape[0]):\n",
    "    lista=add_space(train.Treinamento[linha]).lower()\n",
    "    train.Treinamento[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de um tweet ser relevante ou não no Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42073170731707316\n",
      "0.5792682926829268\n"
     ]
    }
   ],
   "source": [
    "n_relevante=0\n",
    "n_irrelevante=0\n",
    "for numero in train.Classifica:\n",
    "    if numero==0:\n",
    "        n_irrelevante+=1\n",
    "    else:\n",
    "        n_relevante+=1\n",
    "    \n",
    "        \n",
    "P_Relevante_total= n_relevante/(train.shape[0])\n",
    "P_Irrelevante_total=n_irrelevante/(train.shape[0])\n",
    "\n",
    "print(P_Relevante_total)\n",
    "print(P_Irrelevante_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando elementos do DataFrame e Removendo as repetições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista=[]\n",
    "while i<len(train.Treinamento):\n",
    "    lista.append(train.Treinamento[i].split())\n",
    "    i+=1\n",
    "\n",
    "palavras_separadas=[]\n",
    "for elemento in lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas.append(palavra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_as_palavras=palavras_separadas\n",
    "\n",
    "palavras_sem_repeticoes=[]\n",
    "for i in todas_as_palavras:\n",
    "    if i not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Tabelas Relativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro para tweets relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "relevante=[]\n",
    "irrelevante=[]\n",
    "\n",
    "while i<len(train.Classifica):\n",
    "    if train.Classifica[i]==1:\n",
    "        relevante.append(train.Treinamento[i])\n",
    "        \n",
    "    if train.Classifica[i]==0:\n",
    "        irrelevante.append(train.Treinamento[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(relevante):\n",
    "    nova_lista.append(relevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_relevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_relevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     faltou\n",
       "1          a\n",
       "2       coca\n",
       "3       cola\n",
       "4        afe\n",
       "5     pipoca\n",
       "6       coca\n",
       "7       cola\n",
       "8    celular\n",
       "9         no\n",
       "dtype: object"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series(palavras_separadas_relevante)\n",
    "serie.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca           0.051591\n",
       "cola           0.051109\n",
       "e              0.040019\n",
       "de             0.028930\n",
       "eu             0.026519\n",
       "                 ...   \n",
       "pouco          0.000482\n",
       "amassar        0.000482\n",
       "dodochaves1    0.000482\n",
       "sincera        0.000482\n",
       "coé            0.000482\n",
       "Length: 824, dtype: float64"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevante = serie.value_counts(True)\n",
    "tabela_relativa_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando palavras relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_relevante=palavras_separadas_relevante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro para tweets irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(irrelevante):\n",
    "    nova_lista.append(irrelevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_irrelevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_irrelevante.append(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     esqueci\n",
       "1           q\n",
       "2        coca\n",
       "3        cola\n",
       "4     engorda\n",
       "5         vou\n",
       "6      vomita\n",
       "7         ela\n",
       "8    servindo\n",
       "9         ate\n",
       "dtype: object"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_i = pd.Series(palavras_separadas_irrelevante)\n",
    "serie_i.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca       0.044005\n",
       "cola       0.043414\n",
       "de         0.029238\n",
       "a          0.028352\n",
       "e          0.024217\n",
       "             ...   \n",
       "arrotar    0.000295\n",
       "canção     0.000295\n",
       "💳          0.000295\n",
       "clero      0.000295\n",
       "nossa      0.000295\n",
       "Length: 1342, dtype: float64"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevante = serie_i.value_counts(True)\n",
    "tabela_relativa_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_irrelevante=palavras_separadas_irrelevante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas palavras do nosso DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras=[]\n",
    "todas_palavras=(total_palavras_relevante+total_palavras_irrelevante)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\\hspace{3cm}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando para o nosso projeto: \n",
    "\n",
    "$$P(R|tweet)=\\frac{P(tweet|R)P(R)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(tweet|I)P(I)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "              Com isso, podemos remover a divisão pela P(tweet), visto que os dois contem o mesmo denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007232401157184185\n",
      "0.0005906674542232723\n"
     ]
    }
   ],
   "source": [
    "def probabilidade_conjunto(palavra, tabela_classificacao, total_palavras_classificacao):\n",
    "    if palavra not in total_palavras_classificacao:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        frequencia=tabela_classificacao[palavra]\n",
    "        return frequencia\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante))\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aplicando a Suavização de Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_sem_repeticoes=[]\n",
    "palavras_separadas=palavras_separadas_relevante+palavras_separadas_irrelevante\n",
    "\n",
    "for elemento in palavras_separadas:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025570764182716025\n",
      "0.00019055240286692502\n"
     ]
    }
   ],
   "source": [
    "def laplace(prob_dado_classificacao,todas_palavras_classificacao):\n",
    "    numerador=(prob_dado_classificacao+1)\n",
    "    denominador=(len(palavras_sem_repeticoes)+len(todas_palavras_classificacao))\n",
    "    l= numerador/denominador\n",
    "    return l\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_relevante))\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_irrelevante))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_relevancia(tweet):\n",
    "    tweet_lista= tweet.split()\n",
    "#     print(tweet_lista)\n",
    "    \n",
    "    multiplica_relevante=1\n",
    "    multiplica_irrelevante=1\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_relevante,total_palavras_relevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_relevante)\n",
    "        multiplica_relevante *= aplicando_o_laplace\n",
    "\n",
    "#         print(multiplica_relevante)\n",
    "    \n",
    "# Fazendo a mesma coisa, só que agora para os tweets irrelevantes\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_irrelevante)\n",
    "        multiplica_irrelevante*= aplicando_o_laplace\n",
    "\n",
    "#         print(multiplica_irrelevante)\n",
    "\n",
    "   \n",
    "    # Probabilidades de ser relevante e irrelevante\n",
    "\n",
    "    P_relevante= multiplica_relevante*P_Relevante_total\n",
    "    P_irrelevante= multiplica_irrelevante*P_Irrelevante_total\n",
    "    \n",
    "    if  P_relevante>P_irrelevante:\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'\n",
    "    \n",
    "    #     print(P_relevante)\n",
    "    #     print(P_irrelevante)\n",
    "\n",
    "#Testando (Debugando)\n",
    "# print(verifica_relevancia('coca cola é o maior erro do ser humano'))\n",
    "# print(verifica_relevancia('tomei muita água e um pouco de coca cola'))\n",
    "# print(verifica_relevancia('tomando coca cola p dps reclamar de azia'))\n",
    "# print(verifica_relevancia('sim, pior que coca-cola'))\n",
    "# print(verifica_relevancia('preciso curar meu vício na coca cola pprt'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removendo [!-.:?;@]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-648-d08c311d0372>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Teste[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(test.shape[0]):\n",
    "    lista=cleanup(test.Teste[linha]).lower()\n",
    "    test.Teste[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Removendo espaços e emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "# search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-650-d55bccf96dc2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Teste[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(test.shape[0]):\n",
    "    lista=add_space(test.Teste[linha]).lower()\n",
    "    test.Teste[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de um tweet ser relevante ou não no Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45248868778280543\n",
      "0.5475113122171946\n"
     ]
    }
   ],
   "source": [
    "n_relevante=0\n",
    "n_irrelevante=0\n",
    "for numero in test.Classifica:\n",
    "    if numero==0:\n",
    "        n_irrelevante+=1\n",
    "    else:\n",
    "        n_relevante+=1\n",
    "    \n",
    "        \n",
    "P_Relevante_total= n_relevante/(test.shape[0])\n",
    "P_Irrelevante_total=n_irrelevante/(test.shape[0])\n",
    "\n",
    "print(P_Relevante_total)\n",
    "print(P_Irrelevante_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista=[]\n",
    "while i<len(test.Teste):\n",
    "    lista.append(test.Teste[i].split())\n",
    "    i+=1\n",
    "\n",
    "palavras_separadas=[]\n",
    "for elemento in lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas.append(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_as_palavras=palavras_separadas\n",
    "\n",
    "palavras_sem_repeticoes=[]\n",
    "for elemento in todas_as_palavras:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de palavras relevantes e irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "relevante=[]\n",
    "irrelevante=[]\n",
    "\n",
    "while i<len(test.Classifica):\n",
    "    if test.Classifica[i]==1:\n",
    "        relevante.append(test.Teste[i])\n",
    "        \n",
    "    if test.Classifica[i]==0:\n",
    "        irrelevante.append(test.Teste[i])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabelas Relativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(relevante):\n",
    "    nova_lista.append(relevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_relevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_relevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lilkayfr_\n",
       "1          uma\n",
       "2     cocacola\n",
       "3        seria\n",
       "4       melhor\n",
       "5          sou\n",
       "6          tão\n",
       "7      viciado\n",
       "8           em\n",
       "9         coca\n",
       "dtype: object"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series(palavras_separadas_relevante)\n",
    "serie.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabela Relativa dos Tweets Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca         0.052838\n",
       "cola         0.046967\n",
       "de           0.039791\n",
       "e            0.032616\n",
       "eu           0.022831\n",
       "               ...   \n",
       "feijoada     0.000652\n",
       "tio          0.000652\n",
       "relatos      0.000652\n",
       "bolo         0.000652\n",
       "ideologia    0.000652\n",
       "Length: 632, dtype: float64"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevante = serie.value_counts(True)\n",
    "tabela_relativa_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Todas palavras relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_relevante=palavras_separadas_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora fazendo a tabela relativa irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(irrelevante):\n",
    "    nova_lista.append(irrelevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_irrelevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_irrelevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    henricostaa\n",
       "1           água\n",
       "2           coca\n",
       "3           cola\n",
       "4              e\n",
       "5        maizena\n",
       "6           tiro\n",
       "7              e\n",
       "8          queda\n",
       "9             na\n",
       "dtype: object"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_i = pd.Series(palavras_separadas_irrelevante)\n",
    "serie_i.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca               0.040346\n",
       "cola               0.037944\n",
       "de                 0.028338\n",
       "o                  0.024496\n",
       "e                  0.024015\n",
       "                     ...   \n",
       "ruins              0.000480\n",
       "açai               0.000480\n",
       "allanldsantos      0.000480\n",
       "hahahahahaha       0.000480\n",
       "bondedoscriasph    0.000480\n",
       "Length: 989, dtype: float64"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevante = serie_i.value_counts(True)\n",
    "tabela_relativa_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todas palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_irrelevante=palavras_separadas_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas palavras do nosso DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras=[]\n",
    "todas_palavras=(total_palavras_relevante+total_palavras_irrelevante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\\hspace{3cm}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando para o nosso projeto: \n",
    "\n",
    "$$P(R|tweet)=\\frac{P(tweet|R)P(R)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(tweet|I)P(I)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "              Com isso, podemos remover a divisão pela P(tweet), visto que os dois contem o mesmo denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006523157208088715\n",
      "0.0009606147934678194\n"
     ]
    }
   ],
   "source": [
    "def probabilidade_conjunto(palavra, tabela_classificacao, total_palavras_classificacao):\n",
    "    if palavra not in total_palavras_classificacao:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        frequencia=tabela_classificacao[palavra]\n",
    "        return frequencia\n",
    "# Exemplo:\n",
    "\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante))\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_sem_repeticoes=[]\n",
    "palavras_separadas=palavras_separadas_relevante+palavras_separadas_irrelevante\n",
    "\n",
    "for elemento in palavras_separadas:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00034082163341989406\n",
      "0.000287219688606447\n"
     ]
    }
   ],
   "source": [
    "def laplace(prob_dado_classificacao,todas_palavras_classificacao):\n",
    "    numerador=(prob_dado_classificacao+1)\n",
    "    denominador=(len(palavras_sem_repeticoes)+len(todas_palavras_classificacao))\n",
    "    l= numerador/denominador\n",
    "    return l\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_relevante))\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_irrelevante))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_relevancia(tweet):\n",
    "    tweet_lista= tweet.split()\n",
    "#     print(tweet_lista)\n",
    "    \n",
    "    multiplica_relevante=1\n",
    "    multiplica_irrelevante=1\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_relevante,total_palavras_relevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_relevante)\n",
    "        multiplica_relevante *= aplicando_o_laplace\n",
    "\n",
    "#     print(multiplica_relevante)\n",
    "    \n",
    "# Fazendo a mesma coisa, só que agora para os tweets irrelevantes\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_irrelevante)\n",
    "        multiplica_irrelevante*= aplicando_o_laplace\n",
    "\n",
    "#     print(multiplica_irrelevante)\n",
    "    \n",
    "#Probabilidades de ser relevante e irrelevante   \n",
    "    P_relevante= multiplica_relevante*P_Relevante_total\n",
    "    P_irrelevante= multiplica_irrelevante*P_Irrelevante_total\n",
    "    \n",
    "    if  P_relevante>P_irrelevante:\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'\n",
    "\n",
    "    \n",
    "#     print(P_relevante)\n",
    "#     print(P_irrelevante)\n",
    "    \n",
    "\n",
    "#Testando (Debugando)\n",
    "# print(verifica_relevancia('uma cocacola seria melhor'))\n",
    "# print(verifica_relevancia('coca cola é o maior erro do ser humano'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lilkayfr_ uma cocacola seria melhor</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>henricostaa água coca cola e maizena tiro e qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gfmitsuya meu irmao derrubou coca cola nele na...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depois de 2 e 17 dias eu voltei a beber um cop...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o todynho pra segurar a onda do infarto do ene...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>o brasil me obriga a beber\\n\\ncoca cola</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guaraná melhor que coca cola sim pretty poison...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sou tão viciado em coca cola que já estou até ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coca cola é o maior erro do ser humano</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comendo coxinha c coca cola essa hora 👏🏻🤡</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica Relevancia\n",
       "0                lilkayfr_ uma cocacola seria melhor           1  Relevante\n",
       "1  henricostaa água coca cola e maizena tiro e qu...           0  Relevante\n",
       "2  gfmitsuya meu irmao derrubou coca cola nele na...           0  Relevante\n",
       "3  depois de 2 e 17 dias eu voltei a beber um cop...           0  Relevante\n",
       "4  o todynho pra segurar a onda do infarto do ene...           0  Relevante\n",
       "5            o brasil me obriga a beber\\n\\ncoca cola           0  Relevante\n",
       "6  guaraná melhor que coca cola sim pretty poison...           0  Relevante\n",
       "7  sou tão viciado em coca cola que já estou até ...           1  Relevante\n",
       "8             coca cola é o maior erro do ser humano           0  Relevante\n",
       "9          comendo coxinha c coca cola essa hora 👏🏻🤡           0  Relevante"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Relevancia']=test.Teste.apply(verifica_relevancia)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando a qualidade do nosso classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos: 45.248868778280546 %\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos=test.loc[(test['Relevancia']== 'Relevante') & (test['Classifica']==1),:].shape[0]\n",
    "print(f'Verdadeiros positivos: {(verdadeiros_positivos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de falsos positivos (mensagens irrelevantes e que são classificadas como relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos positivos: 54.75113122171946 %\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos=test.loc[(test['Relevancia']== 'Relevante') & (test['Classifica']==0),:].shape[0]\n",
    "print(f'Falsos positivos: {(falsos_positivos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros negativos: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos=test.loc[(test['Relevancia']== 'Irrelevante') & (test['Classifica']==0),:].shape[0]\n",
    "print(f'Verdadeiros negativos: {(verdadeiros_negativos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de falsos negativos (mensagens relevantes e que são classificadas como irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos negativos: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos=test.loc[(test['Relevancia']=='Irrelevante') & (test['Classifica']==1),:].shape[0]\n",
    "print(f'Falsos negativos: {(falsos_negativos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acurácia (mensagens corretamente classificadas, independente da categoria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi de: 45.248868778280546 %\n"
     ]
    }
   ],
   "source": [
    "print(f'A acurácia foi de: {((verdadeiros_positivos+verdadeiros_negativos)/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No nosso projeto, realizamos diversas etapas, dentre elas, a classificação manual de tweets relacionados ao produto Coca-Cola. Posteriormente, começamos pela limpeza do nosso DataFrame, removendo caractericas que julgamos necessárias, além do espaçamento entre palavras e emojis. Após isso, criamos tabelas relativas a partir de cada classificação (Relevante e Irrelevante). Com isso em mãos, fizemos duas equações para depois facilitar o processo de verificar a relevância de um deteminado tweet aleatório. A primeira equação foi a def probabilidade_conjunto, na qual tinhamos como objetivo descobrir a frequência de uma palavra dentro da tabela relativa da própia. Após isso, fizemos a suavização de Laplace através da função def laplace, afim de sanar possíveis erros de quando uma palavra que não aparece na nossa base de dados fosse implementada, dando assim, uma probabilidade muito pequena nessas ocasiões. A partir disso, realizamos uma classificação final (def verifica_relevancia), que incluia todos os passos descritos, retornando a partir da análise de cada palavra se aquele tweet recebido seria Relevante ou Irrelevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contudo, ocorreu um erro inesperado dentro de nosso projeto, uma vez que todos tweets estavam sendo classificados como Relevantes, fazendo com que etapas posteriores como o cálculo da porcentagem de tweets e acurácia resultassem em valores que não condizem com a realidade. Em nosso ponto de vista, esse erro se deu possivelmente pelo balanceamento de tweets na classificação (apesar de serem valores bem próximos, com menos de 10% de distância entre cada classificação). Outro possível motivo é a similaridade entre palavras de diferentes classificações fazendo com que uma classificação seja favorecida em relação a outra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Buscamos resolver esse problema de diversas formas, desde contato com a nossa professora, até contato com os ninjas. Todas recomendações por eles foram seguidas a risca (como debugar o código, dar prints linha por linha em cada função, e pesquisar por possíveis soluções) e da mesma forma não foi possível ter êxito. Por fim, entramos com um contato com um dos ninjas e o mesmo afirmou que não havia erro no código em si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
