{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gustavo Pacil√©o Borba\n",
    "\n",
    "Nome: Julia de Carvalho Figueiredo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\gubor\\OneDrive\\Documentos\\Projeto\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'coca-cola-projeto.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esqueci q coca cola engorda vou vomita</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faltou a coca cola afe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ela servindo ate em comercial mdssss o esmurro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoje a experi√™ncia gastron√¥mica aqui de casa f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pipoca coca cola celular no carregar vendo as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica\n",
       "0             esqueci q coca cola engorda vou vomita           0\n",
       "1                             faltou a coca cola afe           1\n",
       "2  ela servindo ate em comercial mdssss o esmurro...           0\n",
       "3  hoje a experi√™ncia gastron√¥mica aqui de casa f...           0\n",
       "4  pipoca coca cola celular no carregar vendo as ...           1"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lilkayfr_ uma coca-cola seria melhor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@henricostaa √°gua, coca cola e maizena. tiro e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@gfmitsuya meu irmao derrubou coca cola nele n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depois de 2 e 17 dias eu voltei a beber um cop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o todynho pra segurar a onda do infarto do ene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica\n",
       "0              @lilkayfr_ uma coca-cola seria melhor           1\n",
       "1  @henricostaa √°gua, coca cola e maizena. tiro e...           0\n",
       "2  @gfmitsuya meu irmao derrubou coca cola nele n...           0\n",
       "3  depois de 2 e 17 dias eu voltei a beber um cop...           0\n",
       "4  o todynho pra segurar a onda do infarto do ene...           0"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "No nosso projeto, decidimos analisar os tweets relacionados ao produto Coca-cola e assim classificamos como relevante todos tweets que apresentam opini√£o positiva em rela√ß√£o a esse refrigerante, e como irrelevantes aqueles que apresentam um opini√£o contra ao produto ou que n√£o demontra posicionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o de Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removendo [!-.:?;@]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-624-050129bfa610>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Treinamento[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(train.shape[0]):\n",
    "    lista=cleanup(train.Treinamento[linha]).lower()\n",
    "    train.Treinamento[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Removendo espa√ßos e emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "# search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-626-638747a86c95>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Treinamento[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(train.shape[0]):\n",
    "    lista=add_space(train.Treinamento[linha]).lower()\n",
    "    train.Treinamento[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de um tweet ser relevante ou n√£o no Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42073170731707316\n",
      "0.5792682926829268\n"
     ]
    }
   ],
   "source": [
    "n_relevante=0\n",
    "n_irrelevante=0\n",
    "for numero in train.Classifica:\n",
    "    if numero==0:\n",
    "        n_irrelevante+=1\n",
    "    else:\n",
    "        n_relevante+=1\n",
    "    \n",
    "        \n",
    "P_Relevante_total= n_relevante/(train.shape[0])\n",
    "P_Irrelevante_total=n_irrelevante/(train.shape[0])\n",
    "\n",
    "print(P_Relevante_total)\n",
    "print(P_Irrelevante_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando elementos do DataFrame e Removendo as repeti√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista=[]\n",
    "while i<len(train.Treinamento):\n",
    "    lista.append(train.Treinamento[i].split())\n",
    "    i+=1\n",
    "\n",
    "palavras_separadas=[]\n",
    "for elemento in lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas.append(palavra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_as_palavras=palavras_separadas\n",
    "\n",
    "palavras_sem_repeticoes=[]\n",
    "for i in todas_as_palavras:\n",
    "    if i not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Tabelas Relativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro para tweets relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "relevante=[]\n",
    "irrelevante=[]\n",
    "\n",
    "while i<len(train.Classifica):\n",
    "    if train.Classifica[i]==1:\n",
    "        relevante.append(train.Treinamento[i])\n",
    "        \n",
    "    if train.Classifica[i]==0:\n",
    "        irrelevante.append(train.Treinamento[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(relevante):\n",
    "    nova_lista.append(relevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_relevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_relevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     faltou\n",
       "1          a\n",
       "2       coca\n",
       "3       cola\n",
       "4        afe\n",
       "5     pipoca\n",
       "6       coca\n",
       "7       cola\n",
       "8    celular\n",
       "9         no\n",
       "dtype: object"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series(palavras_separadas_relevante)\n",
    "serie.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca           0.051591\n",
       "cola           0.051109\n",
       "e              0.040019\n",
       "de             0.028930\n",
       "eu             0.026519\n",
       "                 ...   \n",
       "pouco          0.000482\n",
       "amassar        0.000482\n",
       "dodochaves1    0.000482\n",
       "sincera        0.000482\n",
       "co√©            0.000482\n",
       "Length: 824, dtype: float64"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevante = serie.value_counts(True)\n",
    "tabela_relativa_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando palavras relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_relevante=palavras_separadas_relevante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro para tweets irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(irrelevante):\n",
    "    nova_lista.append(irrelevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_irrelevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_irrelevante.append(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     esqueci\n",
       "1           q\n",
       "2        coca\n",
       "3        cola\n",
       "4     engorda\n",
       "5         vou\n",
       "6      vomita\n",
       "7         ela\n",
       "8    servindo\n",
       "9         ate\n",
       "dtype: object"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_i = pd.Series(palavras_separadas_irrelevante)\n",
    "serie_i.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca       0.044005\n",
       "cola       0.043414\n",
       "de         0.029238\n",
       "a          0.028352\n",
       "e          0.024217\n",
       "             ...   \n",
       "arrotar    0.000295\n",
       "can√ß√£o     0.000295\n",
       "üí≥          0.000295\n",
       "clero      0.000295\n",
       "nossa      0.000295\n",
       "Length: 1342, dtype: float64"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevante = serie_i.value_counts(True)\n",
    "tabela_relativa_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_irrelevante=palavras_separadas_irrelevante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas palavras do nosso DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras=[]\n",
    "todas_palavras=(total_palavras_relevante+total_palavras_irrelevante)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\\hspace{3cm}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando para o nosso projeto: \n",
    "\n",
    "$$P(R|tweet)=\\frac{P(tweet|R)P(R)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(tweet|I)P(I)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "              Com isso, podemos remover a divis√£o pela P(tweet), visto que os dois contem o mesmo denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007232401157184185\n",
      "0.0005906674542232723\n"
     ]
    }
   ],
   "source": [
    "def probabilidade_conjunto(palavra, tabela_classificacao, total_palavras_classificacao):\n",
    "    if palavra not in total_palavras_classificacao:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        frequencia=tabela_classificacao[palavra]\n",
    "        return frequencia\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante))\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aplicando a Suaviza√ß√£o de Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_sem_repeticoes=[]\n",
    "palavras_separadas=palavras_separadas_relevante+palavras_separadas_irrelevante\n",
    "\n",
    "for elemento in palavras_separadas:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025570764182716025\n",
      "0.00019055240286692502\n"
     ]
    }
   ],
   "source": [
    "def laplace(prob_dado_classificacao,todas_palavras_classificacao):\n",
    "    numerador=(prob_dado_classificacao+1)\n",
    "    denominador=(len(palavras_sem_repeticoes)+len(todas_palavras_classificacao))\n",
    "    l= numerador/denominador\n",
    "    return l\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_relevante))\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_irrelevante))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifica√ß√£o Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_relevancia(tweet):\n",
    "    tweet_lista= tweet.split()\n",
    "#     print(tweet_lista)\n",
    "    \n",
    "    multiplica_relevante=1\n",
    "    multiplica_irrelevante=1\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_relevante,total_palavras_relevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_relevante)\n",
    "        multiplica_relevante *= aplicando_o_laplace\n",
    "\n",
    "#         print(multiplica_relevante)\n",
    "    \n",
    "# Fazendo a mesma coisa, s√≥ que agora para os tweets irrelevantes\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_irrelevante)\n",
    "        multiplica_irrelevante*= aplicando_o_laplace\n",
    "\n",
    "#         print(multiplica_irrelevante)\n",
    "\n",
    "   \n",
    "    # Probabilidades de ser relevante e irrelevante\n",
    "\n",
    "    P_relevante= multiplica_relevante*P_Relevante_total\n",
    "    P_irrelevante= multiplica_irrelevante*P_Irrelevante_total\n",
    "    \n",
    "    if  P_relevante>P_irrelevante:\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'\n",
    "    \n",
    "    #     print(P_relevante)\n",
    "    #     print(P_irrelevante)\n",
    "\n",
    "#Testando (Debugando)\n",
    "# print(verifica_relevancia('coca cola √© o maior erro do ser humano'))\n",
    "# print(verifica_relevancia('tomei muita √°gua e um pouco de coca cola'))\n",
    "# print(verifica_relevancia('tomando coca cola p dps reclamar de azia'))\n",
    "# print(verifica_relevancia('sim, pior que coca-cola'))\n",
    "# print(verifica_relevancia('preciso curar meu v√≠cio na coca cola pprt'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o de Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removendo [!-.:?;@]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;@]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-648-d08c311d0372>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Teste[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(test.shape[0]):\n",
    "    lista=cleanup(test.Teste[linha]).lower()\n",
    "    test.Teste[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Removendo espa√ßos e emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "# search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-650-d55bccf96dc2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Teste[linha]=lista\n"
     ]
    }
   ],
   "source": [
    "for linha in range(test.shape[0]):\n",
    "    lista=add_space(test.Teste[linha]).lower()\n",
    "    test.Teste[linha]=lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de um tweet ser relevante ou n√£o no Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45248868778280543\n",
      "0.5475113122171946\n"
     ]
    }
   ],
   "source": [
    "n_relevante=0\n",
    "n_irrelevante=0\n",
    "for numero in test.Classifica:\n",
    "    if numero==0:\n",
    "        n_irrelevante+=1\n",
    "    else:\n",
    "        n_relevante+=1\n",
    "    \n",
    "        \n",
    "P_Relevante_total= n_relevante/(test.shape[0])\n",
    "P_Irrelevante_total=n_irrelevante/(test.shape[0])\n",
    "\n",
    "print(P_Relevante_total)\n",
    "print(P_Irrelevante_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista=[]\n",
    "while i<len(test.Teste):\n",
    "    lista.append(test.Teste[i].split())\n",
    "    i+=1\n",
    "\n",
    "palavras_separadas=[]\n",
    "for elemento in lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas.append(palavra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_as_palavras=palavras_separadas\n",
    "\n",
    "palavras_sem_repeticoes=[]\n",
    "for elemento in todas_as_palavras:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de palavras relevantes e irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "relevante=[]\n",
    "irrelevante=[]\n",
    "\n",
    "while i<len(test.Classifica):\n",
    "    if test.Classifica[i]==1:\n",
    "        relevante.append(test.Teste[i])\n",
    "        \n",
    "    if test.Classifica[i]==0:\n",
    "        irrelevante.append(test.Teste[i])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabelas Relativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(relevante):\n",
    "    nova_lista.append(relevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_relevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_relevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lilkayfr_\n",
       "1          uma\n",
       "2     cocacola\n",
       "3        seria\n",
       "4       melhor\n",
       "5          sou\n",
       "6          t√£o\n",
       "7      viciado\n",
       "8           em\n",
       "9         coca\n",
       "dtype: object"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series(palavras_separadas_relevante)\n",
    "serie.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabela Relativa dos Tweets Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca         0.052838\n",
       "cola         0.046967\n",
       "de           0.039791\n",
       "e            0.032616\n",
       "eu           0.022831\n",
       "               ...   \n",
       "feijoada     0.000652\n",
       "tio          0.000652\n",
       "relatos      0.000652\n",
       "bolo         0.000652\n",
       "ideologia    0.000652\n",
       "Length: 632, dtype: float64"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevante = serie.value_counts(True)\n",
    "tabela_relativa_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Todas palavras relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_relevante=palavras_separadas_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora fazendo a tabela relativa irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nova_lista=[]\n",
    "while i<len(irrelevante):\n",
    "    nova_lista.append(irrelevante[i].split())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas_irrelevante=[]\n",
    "for elemento in nova_lista:\n",
    "    for palavra in elemento:\n",
    "        palavras_separadas_irrelevante.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    henricostaa\n",
       "1           √°gua\n",
       "2           coca\n",
       "3           cola\n",
       "4              e\n",
       "5        maizena\n",
       "6           tiro\n",
       "7              e\n",
       "8          queda\n",
       "9             na\n",
       "dtype: object"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_i = pd.Series(palavras_separadas_irrelevante)\n",
    "serie_i.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coca               0.040346\n",
       "cola               0.037944\n",
       "de                 0.028338\n",
       "o                  0.024496\n",
       "e                  0.024015\n",
       "                     ...   \n",
       "ruins              0.000480\n",
       "a√ßai               0.000480\n",
       "allanldsantos      0.000480\n",
       "hahahahahaha       0.000480\n",
       "bondedoscriasph    0.000480\n",
       "Length: 989, dtype: float64"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevante = serie_i.value_counts(True)\n",
    "tabela_relativa_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todas palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras_irrelevante=palavras_separadas_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas palavras do nosso DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras=[]\n",
    "todas_palavras=(total_palavras_relevante+total_palavras_irrelevante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\\hspace{3cm}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando para o nosso projeto: \n",
    "\n",
    "$$P(R|tweet)=\\frac{P(tweet|R)P(R)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(tweet|I)P(I)}{P(tweet)}\\hspace{3cm}$$\n",
    "\n",
    "              Com isso, podemos remover a divis√£o pela P(tweet), visto que os dois contem o mesmo denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006523157208088715\n",
      "0.0009606147934678194\n"
     ]
    }
   ],
   "source": [
    "def probabilidade_conjunto(palavra, tabela_classificacao, total_palavras_classificacao):\n",
    "    if palavra not in total_palavras_classificacao:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        frequencia=tabela_classificacao[palavra]\n",
    "        return frequencia\n",
    "# Exemplo:\n",
    "\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante))\n",
    "print(probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_sem_repeticoes=[]\n",
    "palavras_separadas=palavras_separadas_relevante+palavras_separadas_irrelevante\n",
    "\n",
    "for elemento in palavras_separadas:\n",
    "    if elemento not in palavras_sem_repeticoes:\n",
    "        palavras_sem_repeticoes.append(elemento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00034082163341989406\n",
      "0.000287219688606447\n"
     ]
    }
   ],
   "source": [
    "def laplace(prob_dado_classificacao,todas_palavras_classificacao):\n",
    "    numerador=(prob_dado_classificacao+1)\n",
    "    denominador=(len(palavras_sem_repeticoes)+len(todas_palavras_classificacao))\n",
    "    l= numerador/denominador\n",
    "    return l\n",
    "\n",
    "\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_relevante,total_palavras_relevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_relevante))\n",
    "# Exemplo:\n",
    "prob_dado_classificacao=probabilidade_conjunto('amo',tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "print(laplace(prob_dado_classificacao,total_palavras_irrelevante))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_relevancia(tweet):\n",
    "    tweet_lista= tweet.split()\n",
    "#     print(tweet_lista)\n",
    "    \n",
    "    multiplica_relevante=1\n",
    "    multiplica_irrelevante=1\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_relevante,total_palavras_relevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_relevante)\n",
    "        multiplica_relevante *= aplicando_o_laplace\n",
    "\n",
    "#     print(multiplica_relevante)\n",
    "    \n",
    "# Fazendo a mesma coisa, s√≥ que agora para os tweets irrelevantes\n",
    "\n",
    "    for palavra in tweet_lista:\n",
    "        prob_classifica= probabilidade_conjunto(palavra,tabela_relativa_irrelevante,total_palavras_irrelevante)\n",
    "        aplicando_o_laplace= laplace(prob_classifica,total_palavras_irrelevante)\n",
    "        multiplica_irrelevante*= aplicando_o_laplace\n",
    "\n",
    "#     print(multiplica_irrelevante)\n",
    "    \n",
    "#Probabilidades de ser relevante e irrelevante   \n",
    "    P_relevante= multiplica_relevante*P_Relevante_total\n",
    "    P_irrelevante= multiplica_irrelevante*P_Irrelevante_total\n",
    "    \n",
    "    if  P_relevante>P_irrelevante:\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'\n",
    "\n",
    "    \n",
    "#     print(P_relevante)\n",
    "#     print(P_irrelevante)\n",
    "    \n",
    "\n",
    "#Testando (Debugando)\n",
    "# print(verifica_relevancia('uma cocacola seria melhor'))\n",
    "# print(verifica_relevancia('coca cola √© o maior erro do ser humano'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lilkayfr_ uma cocacola seria melhor</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>henricostaa √°gua coca cola e maizena tiro e qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gfmitsuya meu irmao derrubou coca cola nele na...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depois de 2 e 17 dias eu voltei a beber um cop...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o todynho pra segurar a onda do infarto do ene...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>o brasil me obriga a beber\\n\\ncoca cola</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guaran√° melhor que coca cola sim pretty poison...</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sou t√£o viciado em coca cola que j√° estou at√© ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coca cola √© o maior erro do ser humano</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comendo coxinha c coca cola essa hora üëèüèªü§°</td>\n",
       "      <td>0</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica Relevancia\n",
       "0                lilkayfr_ uma cocacola seria melhor           1  Relevante\n",
       "1  henricostaa √°gua coca cola e maizena tiro e qu...           0  Relevante\n",
       "2  gfmitsuya meu irmao derrubou coca cola nele na...           0  Relevante\n",
       "3  depois de 2 e 17 dias eu voltei a beber um cop...           0  Relevante\n",
       "4  o todynho pra segurar a onda do infarto do ene...           0  Relevante\n",
       "5            o brasil me obriga a beber\\n\\ncoca cola           0  Relevante\n",
       "6  guaran√° melhor que coca cola sim pretty poison...           0  Relevante\n",
       "7  sou t√£o viciado em coca cola que j√° estou at√© ...           1  Relevante\n",
       "8             coca cola √© o maior erro do ser humano           0  Relevante\n",
       "9          comendo coxinha c coca cola essa hora üëèüèªü§°           0  Relevante"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Relevancia']=test.Teste.apply(verifica_relevancia)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando a qualidade do nosso classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de verdadeiros positivos (mensagens relevantes e que s√£o classificadas como relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos: 45.248868778280546 %\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos=test.loc[(test['Relevancia']== 'Relevante') & (test['Classifica']==1),:].shape[0]\n",
    "print(f'Verdadeiros positivos: {(verdadeiros_positivos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de falsos positivos (mensagens irrelevantes e que s√£o classificadas como relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos positivos: 54.75113122171946 %\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos=test.loc[(test['Relevancia']== 'Relevante') & (test['Classifica']==0),:].shape[0]\n",
    "print(f'Falsos positivos: {(falsos_positivos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de verdadeiros negativos (mensagens irrelevantes e que s√£o classificadas como irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros negativos: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos=test.loc[(test['Relevancia']== 'Irrelevante') & (test['Classifica']==0),:].shape[0]\n",
    "print(f'Verdadeiros negativos: {(verdadeiros_negativos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Porcentagem de falsos negativos (mensagens relevantes e que s√£o classificadas como irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos negativos: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos=test.loc[(test['Relevancia']=='Irrelevante') & (test['Classifica']==1),:].shape[0]\n",
    "print(f'Falsos negativos: {(falsos_negativos/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acur√°cia (mensagens corretamente classificadas, independente da categoria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acur√°cia foi de: 45.248868778280546 %\n"
     ]
    }
   ],
   "source": [
    "print(f'A acur√°cia foi de: {((verdadeiros_positivos+verdadeiros_negativos)/test.shape[0])*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No nosso projeto, realizamos diversas etapas, dentre elas, a classifica√ß√£o manual de tweets relacionados ao produto Coca-Cola. Posteriormente, come√ßamos pela limpeza do nosso DataFrame, removendo caractericas que julgamos necess√°rias, al√©m do espa√ßamento entre palavras e emojis. Ap√≥s isso, criamos tabelas relativas a partir de cada classifica√ß√£o (Relevante e Irrelevante). Com isso em m√£os, fizemos duas equa√ß√µes para depois facilitar o processo de verificar a relev√¢ncia de um deteminado tweet aleat√≥rio. A primeira equa√ß√£o foi a def probabilidade_conjunto, na qual tinhamos como objetivo descobrir a frequ√™ncia de uma palavra dentro da tabela relativa da pr√≥pia. Ap√≥s isso, fizemos a suaviza√ß√£o de Laplace atrav√©s da fun√ß√£o def laplace, afim de sanar poss√≠veis erros de quando uma palavra que n√£o aparece na nossa base de dados fosse implementada, dando assim, uma probabilidade muito pequena nessas ocasi√µes. A partir disso, realizamos uma classifica√ß√£o final (def verifica_relevancia), que incluia todos os passos descritos, retornando a partir da an√°lise de cada palavra se aquele tweet recebido seria Relevante ou Irrelevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contudo, ocorreu um erro inesperado dentro de nosso projeto, uma vez que todos tweets estavam sendo classificados como Relevantes, fazendo com que etapas posteriores como o c√°lculo da porcentagem de tweets e acur√°cia resultassem em valores que n√£o condizem com a realidade. Em nosso ponto de vista, esse erro se deu possivelmente pelo balanceamento de tweets na classifica√ß√£o (apesar de serem valores bem pr√≥ximos, com menos de 10% de dist√¢ncia entre cada classifica√ß√£o). Outro poss√≠vel motivo √© a similaridade entre palavras de diferentes classifica√ß√µes fazendo com que uma classifica√ß√£o seja favorecida em rela√ß√£o a outra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Buscamos resolver esse problema de diversas formas, desde contato com a nossa professora, at√© contato com os ninjas. Todas recomenda√ß√µes por eles foram seguidas a risca (como debugar o c√≥digo, dar prints linha por linha em cada fun√ß√£o, e pesquisar por poss√≠veis solu√ß√µes) e da mesma forma n√£o foi poss√≠vel ter √™xito. Por fim, entramos com um contato com um dos ninjas e o mesmo afirmou que n√£o havia erro no c√≥digo em si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
